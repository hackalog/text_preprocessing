{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Text Data\n",
    "The goal of this exploration is to survey and compare various ways of preprocessing text data, mainly with an eye on vector space embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using a cookiecutter approach. There has been some good thought put into this framework, so let's give it a spin and see how well it performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "Created via `cookiecutter https://github.com/drivendata/cookiecutter-data-science`\n",
    "\n",
    "```\n",
    "├── LICENSE\n",
    "├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── external       <- Data from third party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "│\n",
    "├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "│\n",
    "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "│\n",
    "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "│                         `1.0-jqp-initial-data-exploration`.\n",
    "│\n",
    "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "│\n",
    "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "│\n",
    "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "│                         generated with `pip freeze > requirements.txt`\n",
    "│\n",
    "├── src                <- Source code for use in this project.\n",
    "│   ├── __init__.py    <- Makes src a Python module\n",
    "│   │\n",
    "│   ├── data           <- Scripts to download or generate data\n",
    "│   │   └── make_dataset.py\n",
    "│   │\n",
    "│   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "│   │   └── build_features.py\n",
    "│   │\n",
    "│   ├── models         <- Scripts to train models and then use trained models to make\n",
    "│   │   │                 predictions\n",
    "│   │   ├── predict_model.py\n",
    "│   │   └── train_model.py\n",
    "│   │\n",
    "│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "│       └── visualize.py\n",
    "│\n",
    "└── tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull in the data\n",
    "We want to sync up our data. There is glue in the default makefile for syncing with s3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make -f ../Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is a beautiful trick - self-documenting Makefiles. I'm going to steal this and put it in all my makefiles from now on: [Self Documenting Makefile Code](https://github.com/drivendata/cookiecutter-data-science/blob/f891ddeeb43a59c9542375efdb2bb4dcc6ebf826/%7B%7B%20cookiecutter.repo_name%20%7D%7D/Makefile#L107-L144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I added some glue to sync the files somewhere on the filesystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "--- a/Makefile\n",
    "+++ b/Makefile\n",
    "@@ -10,12 +10,24 @@ PROFILE = default\n",
    " PROJECT_NAME = text_preproc\n",
    " PYTHON_INTERPRETER = python3\n",
    " \n",
    "+DATASET=yelp-dataset-11\n",
    "+\n",
    "+RAW_DATA_PATH=$(DATA_REPO)/raw/$(DATASET)\n",
    "+EXTERNAL_DATA_PATH=$(DATA_REPO)/external/$(DATASET)\n",
    "+INTERIM_DATA_PATH=$(DATA_REPO)/interim/$(DATASET)\n",
    "+PROCESSED_DATA_PATH=$(DATA_REPO)/processed/$(DATASET)\n",
    "+\n",
    " ifeq (,$(shell which conda))\n",
    " HAS_CONDA=False\n",
    " else\n",
    " HAS_CONDA=True\n",
    " endif\n",
    " \n",
    "+ifndef DATA_REPO\n",
    "+$(error DATA_REPO environment var needs to be set)\n",
    "+endif\n",
    "+\n",
    "+\n",
    " #################################################################################\n",
    " # COMMANDS                                                                      #\n",
    " #################################################################################\n",
    "@@ -46,6 +58,17 @@ else\n",
    " \taws s3 sync data/ s3://$(BUCKET)/data/ --profile $(PROFILE)\n",
    " endif\n",
    " \n",
    "+## Sync with raw data mountpoint\n",
    "+pull_data:\n",
    "+\tfind $(EXTERNAL_DATA_PATH)/ -name \"*json\" -exec ln -sf {} data/external/ \\;\n",
    "+\trsync -az $(INTERIM_DATA_PATH)/ data/interim/\n",
    "+\trsync -az $(PROCESSED_DATA_PATH)/ data/processed/\n",
    "+\n",
    "+## Sync with raw data mountpoint\n",
    "+push_data:\n",
    "+\trsync -az --delete data/interim/ $(INTERIM_DATA_PATH)/\n",
    "+\trsync -az --delete data/processed/ $(PROCESSED_DATA_PATH)/\n",
    "+\n",
    " ## Download Data from S3\n",
    " sync_data_from_s3:\n",
    " ifeq (default,$(PROFILE))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
